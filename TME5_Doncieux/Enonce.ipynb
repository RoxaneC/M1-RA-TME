{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>TME ROBOTIQUE ET APPRENTISSAGE</font>\n",
    "# <font color='red'>Evolution de structures</font>\n",
    "\n",
    "<font color=\"red\">Version étudiant 2021-2022</font>\n",
    "\n",
    "*mise à jour: 11/04/2022*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook peut être exécuté dans [Google Colab](colab.research.google.com/)\n",
    "\n",
    "Pour faciliter la lisibilité du notebook, le code donné, à écrire ou à compléter est dans les cellules en annexe, à la fin du notebook. Les cellules de réponses ne doivent contenir que les quelques instructions permettant d'afficher les résultats (éventuellement des appels permettant de les générer) et les commentaires d'analyse associés.\n",
    "\n",
    "Vous devez déposer votre travail sur Moodle:\n",
    "* déposer votre notebook, avec le nom de fichier *obligatoirement* au format suivant: **RA_NOM1_NOM2.ipynb**\n",
    "* toutes les cellules exécutées\n",
    "* des graphes et un commentaire sur les résultats obtenus\n",
    "* affichage limité au nécessaire pour assurer la lisibilité du notebook (pas d'affichage de debug ni de centaines de graphes !)\n",
    "\n",
    "*Le sujet est à faire en binome.*\n",
    "\n",
    "# COMPLETEZ LES CHAMPS CI-DESSOUS AVEC NOM/PRENOM/CARTE_ETU:\n",
    "\n",
    "* Étudiant 1: **_Nom_ _Prénom_ _noCarteEtudiant_**\n",
    "* Étudiant 2: **_Nom_ _Prénom_ _noCarteEtudiant_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Ce TME est composé de deux parties indépendantes qui s'appuieront toutes deux sur le framework DEAP que vous avez utilisé lors des TME précédents. \n",
    "\n",
    "Dans la première partie, vous ferez de la regression symbolique avec de la programmation génétique.\n",
    "\n",
    "Dans la seconde partie, vous testerez l'expérience de Lehman et Stanley sur novelty search. \n",
    "\n",
    "Installation des dépendances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install deap\n",
    "!pip install gym\n",
    "!pip install scoop\n",
    "!apt install libgraphviz-dev\n",
    "!pip install pygraphviz\n",
    "!apt install poppler-utils \n",
    "!pip install pdf2image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur les machines de TME (ou sur votre machine), vous pouvez également utiliser singularity, qui est un outil permettant de gérer des \"containers\" contenant tout l'environnement logiciel et les dépendances nécessaires, cf https://sylabs.io/guides/3.5/user-guide/index.html.\n",
    "\n",
    "L'image singularity est disponible sur moodle.\n",
    "\n",
    "Vous devez la copier en local sur votre machine (elle ne doit pas être dans un répertoire accessible par le réseau). Vous pouve ensuite lancer un shell de la façon suivante:\n",
    "<pre>singularity shell TME_RA.sif </pre>\n",
    "Cela vous donnera accès à un shell dans lequel toutes les dépendances sont disponibles. \n",
    "\n",
    "Remarque: singularity attache par défaut votre répertoire home à l'image singularity. C'est très pratique, mais cela peut poser des difficultés en python si vous avez des bibliothèques installées en local. Vous pouvez utiliser l'option --no-home pour éviter ce type de problème. Pour accéder à vos fichiers, vous pouvez alors demander à monter un répertoire particulier dans votre image avec l'argument --bind TME_hors_singularity:/TME_dans_singularity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Regression symbolique\n",
    "\n",
    "Vous allez utiliser la programmation génétique pour retrouver des équations à partir de données. \n",
    "Vous utiliserez pour cela les fonctions proposées par DEAP:\n",
    "https://deap.readthedocs.io/en/master/tutorials/advanced/gp.html et vous pourrez vous inspirez des exemples de programmation génétique donnés dans la documentation: https://deap.readthedocs.io/en/master/examples/gp_symbreg.html.\n",
    "\n",
    "\n",
    "**1.1-** Complétez le code qui vous a été fourni (annexe, question 1-3, `symbolic_regression.py`). En vous appuyant sur DEAP, vous implémenterez 3 stratégies: \n",
    "* une stratégie purement élitiste visant à minimiser l'erreur d'approximation uniquement, \n",
    "* la stratégie avec double tournoi, le premier tournoi choisissant les individus avec les erreurs les plus faibles et le second tournoi choisissant les individus avec le modèle le plus simple\n",
    "* une stratégie multi-objectif s'appuyant sur NSGA-2 avec l'erreur d'approximation comme premier objectif et la taille du modèle en deuxième objectif (les deux étant à minimiser)\n",
    "\n",
    "Vous testerez votre code sur une fonction simple (par exemple f(x,y)=x*y+cos(x)) avec le jeu de fonctions primitives suivant: +, -, *, / (protected_div), cos et sin. Vous pourrez ajouter une constante (1) et une constante éphémère (variable aléatoire uniforme entre -1 et 1). \n",
    "\n",
    "Vous génèrerez un ensemble de données d'entrainement et un ensemble de validation que vous utiliserez pour vérifier s'il y a eu surapprentissage. Vous pourrez générer, par exemple, 30 valeurs différentes de x et 30 valeurs différentes de y. Vous indiquerez dans votre réponse les opérateurs de mutation et de croisement que vous avez utilisés (remarque: si vous voulez combiner plusieurs opérateurs de mutation ou de croisement, il faut définir un nouvel opérateur qui gère cette combinaison).\n",
    "\n",
    "Vous regarderez les arbres générés et indiquerez le nombre de fois que la fonction a été retrouvée sur une dizaine d'expériences. Vous comparerez la taille des fonctions générées selon la variante de sélection utilisée. \n",
    "\n",
    "**Remarque1:** pour rappel, la programmation génétique utilise généralement de grandes populations. Il vous est recommandé d'utiliser des tailles de 400 minimum. En une centaine de générations, vous devriez pouvoir observer de premiers résultats. \n",
    "\n",
    "**Remarque2:** pour limiter l'impact du \"bloat\", il vous est recommandé de mettre une taille maximale à l'arbre généré par les opérateurs de mutation et de croisement. Vous pourrez utiliser gp.staticLimit. Sans cela, certaines expériences risquent de prendre un temps et une mémoire considérables. \n",
    "\n",
    "Complétez le squelette de code donné en annexe. L'exécution de la cellule sauvegardera son contenu que vous pourrez ensuite appeler dans un terminal ou directement depuis le notebook en transmettant les arguments décrivant la variante que vous souhaitez tester (tournoi, nsga2, ...).\n",
    "\n",
    "Vous pourrez afficher des arbres dans votre notebook en vous inspirant du code fourni ou en affichant directement le PDF dans le notebook avec les commandes suivantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"res_dir/hof_tree_genX.pdf\"\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "images = convert_from_path(filepath)\n",
    "images[0]  # first page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<ANSWER>\n",
    "#</ANSWER>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2-** Ajoutez du bruit à vos fonctions et observez le résultat obtenu (mettez des valeurs qui sont faibles devant les données, par exemple 0.0001)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<ANSWER>\n",
    "#</ANSWER>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fitness & Nouveauté\n",
    "\n",
    "L'environnement `FastsimSimpleNavigation-v0` de gym_fastsim permet de lancer des expériences de navigation avec un robot à roues naviguant dans un labyrinthe. Vous allez dans cette partie reproduire les expériences de Lehman et Stanley sur la recherche de nouveauté. Vous allez faire différentes variantes de cette expérience, certaines étant en mono- d'autres étant en multi-objectif. Pour simplifier, dans tous les cas, vous utiliserez NSGA-2, qui est équivalent à une stratégie élitiste en mono-objectif.\n",
    "\n",
    "Pour installer l'environnement dans collab ou jupyter, utiliser les commandes suivantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/sferes2/libfastsim\n",
    "!cd libfastsim && ./waf configure build install\n",
    "!git clone https://github.com/alexendy/pyfastsim\n",
    "!cd pyfastsim && pip install .\n",
    "!git clone https://github.com/alexendy/fastsim_gym\n",
    "!cd fastsim_gym && pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarque: pour une installation sur les machines de TME, vous n'aurez pas les droits pour installer fastsim dans les répertoires système. Dans ce cas, vous pouvez ajouter l'installer dans votre répertoire en ajoutant un argument 'prefix' au waf configure et ajouter le répertoire des libs ainsi créé à la variable d'environnement LIBRARY_PATH et le répertoire des fichiers headers à la variable d'environnement CPATH. Une fois cela fait, vous pouvez faire appel au pip install de pyfastsim puis de fastsim_gym."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1-**  Lancer une première expérience dans laquelle le robot doit atteindre la sortie du labyrinthe. Vous pourrez essayer avec la reward de l'expérience, qui est une reward binaire (sortie atteinte ou non) et avec une fitness plus continue dans laquelle la récompense est la distance à la sortie (à minimiser donc). Pour observer le comportement de la recherche effectuée, vous pourrez écrire la position du robot à la fin de l'évaluation et ensuite tracer ces positions avec les fonctions fournies dans `maze_plot.py` (vous pouvez aussi tracer les trajectoires, mais comme il y a 2000 positions par évaluation, dans ce cas, vous pourrez n'écrire qu'une position sur 100, par exemple).\n",
    "\n",
    "Quelles parties de l'espace ont été explorées dans les deux cas ? Est-ce que la sortie est atteinte (vous vous limiterez à 200 générations) ? Si oui, au bout de combien de générations ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<ANSWER>\n",
    "\n",
    "#</ANSWER>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2-** Lancer la même expérience, mais avec un critère de nouveauté. Vous pourrez pour cela partir du code fourni pour le calcul de nouveauté (`novelty_search.py`) et le compléter.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<ANSWER>\n",
    "\n",
    "#</ANSWER>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3-** Utiliser en même temps la fitness et le critère de nouveauté avec NSGA-2. Mesurez le temps moyen pour atteindre la sortie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<ANSWER>\n",
    "\n",
    "#</ANSWER>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annexes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_cell_magic\n",
    "@register_cell_magic\n",
    "def run_and_save(line, cell):\n",
    "    print(\"Run and save python code block to file: \"+line)\n",
    "    with open(line, 'wt') as fd:\n",
    "        fd.write(cell)\n",
    "    code = compile(cell, line, 'exec')\n",
    "    exec(code, globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.1 à 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile symbolic_regression.py\n",
    "\n",
    "# cellule à compléter au niveau des balises <ANSWER></ANSWER>\n",
    "\n",
    "from deap import creator, gp, base, tools, algorithms\n",
    "import operator\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import argparse\n",
    "import pickle\n",
    "import datetime\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "def protectedDiv(left, right):\n",
    "    try:\n",
    "        return left / right\n",
    "    except ZeroDivisionError:\n",
    "        return 1\n",
    "\n",
    "def ru():\n",
    "    return random.uniform(-1,1)\n",
    "\n",
    "\n",
    "\n",
    "def evalSymbReg(individual, input, output, nb_obj=1):\n",
    "    # Transform the tree expression in a callable function\n",
    "    func = toolbox.compile(expr=individual)\n",
    "    sqerrors=[]\n",
    "    for i in range(len(input)):\n",
    "        sqerrors.append((func(*input[i])-output[i])**2)\n",
    "    if (nb_obj==1):\n",
    "        return math.fsum(sqerrors) / len(sqerrors),\n",
    "    else:\n",
    "        return math.fsum(sqerrors) / len(sqerrors), len(individual)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if (__name__ == \"__main__\"):\n",
    "\n",
    "    random.seed()\n",
    "\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='Launch symbolic regression run.')\n",
    "\n",
    "    parser.add_argument('--nb_gen', type=int, default=200,\n",
    "                        help='number of generations')\n",
    "    parser.add_argument('--mu', type=int, default=400,\n",
    "                        help='population size')\n",
    "    parser.add_argument('--lambda_', type=int, default=400,\n",
    "                        help='number of individuals to generate')\n",
    "    parser.add_argument('--res_dir', type=str, default=\"res\",\n",
    "                        help='basename of the directory in which to put the results')\n",
    "    parser.add_argument('--selection', type=str, default=\"elitist\", choices=['elitist', 'double_tournament', 'nsga2'],\n",
    "                        help='selection scheme')\n",
    "    parser.add_argument('--problem', type=str, default=\"f1\", choices=['f1', 'f2'],\n",
    "                        help='function to fit')\n",
    "\n",
    "    # for question 1.2\n",
    "    parser.add_argument('--noise', type=float, default=\"0.\",\n",
    "                        help='noise added to the model to fit (gaussian, mean=0, sigma=noise)')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    print(\"Number of generations: \"+str(args.nb_gen))\n",
    "    ngen=args.nb_gen\n",
    "    print(\"Population size: \"+str(args.mu))\n",
    "    mu=args.mu\n",
    "    print(\"Number of offspring to generate: \"+str(args.lambda_))\n",
    "    lambda_=args.lambda_\n",
    "    print(\"Selection scheme: \"+str(args.selection))\n",
    "    sel=args.selection\n",
    "    if (sel==\"nsga2\"):\n",
    "        nb_obj=2\n",
    "    else:\n",
    "        nb_obj=1\n",
    "    print(\"Basename of the results dir: \"+str(args.res_dir))\n",
    "    name=args.res_dir\n",
    "\n",
    "    if (nb_obj==1):\n",
    "        creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "    elif (nb_obj==2):\n",
    "        creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,-1.0))\n",
    "\n",
    "    creator.create(\"Individual\", gp.PrimitiveTree, fitness=creator.FitnessMin)\n",
    "\n",
    "    noise=args.noise\n",
    "    problem=args.problem\n",
    "\n",
    "    d=datetime.datetime.today()\n",
    "    if(name!=\"\"):\n",
    "        sep=\"_\"\n",
    "    else:\n",
    "        sep=\"\"\n",
    "    run_name=name+\"_\"+sel+\"_\"+d.strftime(name+sep+\"%Y_%m_%d-%H-%M-%S\")\n",
    "    try:\n",
    "        os.makedirs(run_name)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    print(\"Putting the results in : \"+run_name)\n",
    "\n",
    "    stats_fit = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats_size = tools.Statistics(len)\n",
    "    stats_height = tools.Statistics(lambda ind: ind.height)\n",
    "    mstats = tools.MultiStatistics(fitness=stats_fit, size=stats_size, height=stats_height)\n",
    "    mstats.register(\"avg\", np.mean)\n",
    "    mstats.register(\"std\", np.std)\n",
    "    mstats.register(\"min\", np.min)\n",
    "    mstats.register(\"max\", np.max)\n",
    "    \n",
    "        \n",
    "    if (problem==\"f1\"):\n",
    "        nb_dim=2\n",
    "        input_training=[]\n",
    "        output_training=[]\n",
    "        input_testing=[]\n",
    "        output_testing=[]\n",
    "        name_vars={\"ARG0\": \"x1\", \"ARG1\": \"x2\"}\n",
    "\n",
    "        # Complétez pour générer l'ensemble d'entrainement et de validation avec une fonction choisie à 2 dimensions\n",
    "        #<ANSWER>\n",
    "       \n",
    "        #</ANSWER>\n",
    "    # en OPTION: vous pouvez faire des tests sur d'autres fonctions    \n",
    "    elif (problem==\"f2\"):\n",
    "        #<ANSWER>\n",
    "\n",
    "        #</ANSWER>\n",
    "        \n",
    "    pset = gp.PrimitiveSet(\"MAIN\", nb_dim)\n",
    "\n",
    "    # Complétez pour constituer l'ensemble de primitives qui pourront être utilisées\n",
    "    #<ANSWER>\n",
    "\n",
    "    #</ANSWER>\n",
    "\n",
    "    pset.addTerminal(1)\n",
    "    pset.addEphemeralConstant(\"cst\", ru )\n",
    "    pset.renameArguments(**name_vars)\n",
    "\n",
    "    cxpb=0.5\n",
    "    mutpb=0.1\n",
    "\n",
    "\n",
    "    toolbox = base.Toolbox()\n",
    "\n",
    "    # En vous inspirant des exemples de programmation génétique dans DEAP, \n",
    "    # enregistrez les différents opérateurs que vous utiliserez dans la suite.\n",
    "    # Vous choisirez l'opérateur de sélection en fonction de la variable sel \n",
    "    # (voir valeurs possibles dans le parser d'arguments)\n",
    "    #<ANSWER>\n",
    "\n",
    "    #</ANSWER>\n",
    "    \n",
    "\n",
    "    pop = toolbox.population(n=400)\n",
    "\n",
    "    if (nb_obj==1):\n",
    "        print(\"Hall-of-fame: best solution\")\n",
    "        hof = tools.HallOfFame(1)\n",
    "    else:\n",
    "        print(\"Hall-of-fame: Pareto front\")\n",
    "        hof=tools.ParetoFront()\n",
    "\n",
    "    # Pour simplifier, plutôt que d'écrire la boucle, vous pourrez utiliser un algorithme tout intégré, \n",
    "    # par exemple eaMuPlusLambda (cf https://deap.readthedocs.io/en/master/api/algo.html). \n",
    "    # Cela ne permettra pas de générer un NSGA-II complet, mais cela vous permettra de faire de premiers tests.\n",
    "    # En option, si vous avez le temps, vous pourrez tester un NSGA-II complet pour voir si cela change les résultats.\n",
    "    #<ANSWER>\n",
    "\n",
    "    #</ANSWER>\n",
    "    \n",
    "    # Affichage des résultats. Tout est dans le répertoire run_name\n",
    "    avg,dmin,dmax=log.chapters['fitness'].select(\"avg\", \"min\", \"max\")\n",
    "    gen=log.select(\"gen\")\n",
    "\n",
    "    plt.figure()\n",
    "    plt.yscale(\"log\")\n",
    "    plt.plot(gen[1:],dmin[1:])\n",
    "    plt.title(\"Minimum error\")\n",
    "    plt.savefig(run_name+\"/min_error_gen%d.pdf\"%(ngen))\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.yscale(\"log\")\n",
    "    plt.fill_between(gen[1:], dmin[1:], dmax[1:], alpha=0.25, linewidth=0)\n",
    "    plt.plot(gen[1:],avg[1:])\n",
    "    plt.title(\"Average error\")\n",
    "    plt.savefig(run_name+\"/avg_error_gen%d.pdf\"%(ngen))\n",
    "\n",
    "    avg,dmin,dmax=log.chapters['size'].select(\"avg\", \"min\", \"max\")\n",
    "    gen=log.select(\"gen\")\n",
    "    plt.figure()\n",
    "    plt.yscale(\"log\")\n",
    "    plt.fill_between(gen[1:], dmin[1:], dmax[1:], alpha=0.25, linewidth=0)\n",
    "    plt.plot(gen[1:],avg[1:])\n",
    "    plt.title(\"Average size\")\n",
    "    plt.savefig(run_name+\"/avg_size_gen%d.pdf\"%(ngen))\n",
    "\n",
    "    avg,dmin,dmax=log.chapters['height'].select(\"avg\", \"min\", \"max\")\n",
    "    gen=log.select(\"gen\")\n",
    "    plt.figure()\n",
    "    plt.yscale(\"log\")\n",
    "    plt.fill_between(gen[1:], dmin[1:], dmax[1:], alpha=0.25, linewidth=0)\n",
    "    plt.plot(gen[1:],avg[1:])\n",
    "    plt.title(\"Average height\")\n",
    "    plt.savefig(run_name+\"/avg_height_gen%d.pdf\"%(ngen))\n",
    "        \n",
    "    with open(run_name+\"/pset_gen%d.npz\"%(ngen), 'wb') as f:\n",
    "        pickle.dump(pset, f)\n",
    "\n",
    "\n",
    "    for i,ind in enumerate(hof):\n",
    "        print(\"=========\")\n",
    "        print(\"HOF %d, len=%d\"%(i,len(ind)))\n",
    "        print(\"Error on the training dataset: %f\"%(evalSymbReg(ind, input_training, output_training, nb_obj=1)))\n",
    "        print(\"Error on the testing dataset: %f\"%(evalSymbReg(ind, input_testing, output_testing, nb_obj=1)))\n",
    "        with open(run_name+\"/hof%d_gen%d.npz\"%(i, ngen), 'wb') as f:\n",
    "            pickle.dump(ind, f)\n",
    "\n",
    "        nodes, edges, labels = gp.graph(ind)\n",
    "\n",
    "        ### Graphviz Section ###\n",
    "        import pygraphviz as pgv\n",
    "\n",
    "        plt.figure()\n",
    "\n",
    "        g = pgv.AGraph()\n",
    "        g.add_nodes_from(nodes)\n",
    "        g.add_edges_from(edges)\n",
    "        g.layout(prog=\"dot\")\n",
    "\n",
    "        for ni in nodes:\n",
    "            n = g.get_node(ni)\n",
    "            n.attr[\"label\"] = labels[ni]\n",
    "\n",
    "\n",
    "        g.draw(run_name+\"/hof%d_tree_gen%d.pdf\"%(i,ngen))\n",
    "\n",
    "    print(\"Results saved in \"+run_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code de la question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_and_save maze_plot.py\n",
    "#!/usr/bin/python -w\n",
    "\n",
    "# NE PAS MODIFIER LE CONTENU DE CETTE CELLULE\n",
    "# Cette cellule contient le code de fonctions permettant de tracer les points atteints \n",
    "# par les politiques de navigation générées.\n",
    "# Ce code n'a pas à être modifié ni complété, il suffit d'exécuter la cellule telle quelle.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_points(points, bg=\"maze_hard.pbm\", title=None):\n",
    "    x,y = zip(*points)\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.set_xlim(0,600)\n",
    "    ax1.set_ylim(600,0) # Decreasing\n",
    "    ax1.set_aspect('equal')\n",
    "    if(bg):\n",
    "        img = plt.imread(bg)\n",
    "        ax1.imshow(img, extent=[0, 600, 600, 0])\n",
    "    if(title):\n",
    "        ax1.set_title(title)\n",
    "    ax1.scatter(x, y, s=2)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_points_lists(lpoints, bg=\"maze_hard.pbm\", title=None):\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.set_xlim(0,600)\n",
    "    ax1.set_ylim(600,0) # Decreasing\n",
    "    ax1.set_aspect('equal')\n",
    "    if(bg):\n",
    "        img = plt.imread(bg)\n",
    "        ax1.imshow(img, extent=[0, 600, 600, 0])\n",
    "    if(title):\n",
    "        ax1.set_title(title)\n",
    "    for points in lpoints:\n",
    "        x,y = zip(*points)\n",
    "        ax1.scatter(x, y, s=2)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_points_file(filename, bg=\"maze_hard.pbm\", title=None):\n",
    "    try:\n",
    "        with open(filename) as f:\n",
    "            points=[]\n",
    "            for l in f.readlines():\n",
    "                pos=list(map(float, l.split(\" \")))\n",
    "                points.append(pos)\n",
    "            f.close()\n",
    "            plot_points(points, bg, title)\n",
    "    except IOError:\n",
    "        print(\"Could not read file: \"+f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_and_save nn.py\n",
    "# NE PAS MODIFIER LE CONTENU DE CETTE CELLULE\n",
    "# Cette cellule contient le code de gestion d'une politique au travers d'un réseau de neurones de structure fixe. \n",
    "# Ce code n'a pas à être modifié ni complété, il suffit d'exécuter la cellule telle quelle.\n",
    "\n",
    "# coding: utf-8\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "## Suppress TF info messages\n",
    "\n",
    "import os\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1./(1 + np.exp(-x))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "\n",
    "def gen_simplemlp(n_in, n_out, n_hidden_layers=2, n_neurons_per_hidden=5):\n",
    "    n_neurons = [n_neurons_per_hidden]*n_hidden_layers if np.isscalar(n_neurons_per_hidden) else n_neurons_per_hidden\n",
    "    i = Input(shape=(n_in,))\n",
    "    x = i\n",
    "    for n in n_neurons:\n",
    "        x = Dense(n, activation='sigmoid')(x)\n",
    "    o = Dense(n_out, activation='tanh')(x)\n",
    "    m = Model(inputs=i, outputs=o)\n",
    "    return m\n",
    "    \n",
    "\n",
    "class SimpleNeuralControllerNumpy():\n",
    "    def __init__(self, n_in, n_out, n_hidden_layers=2, n_neurons_per_hidden=5, params=None):\n",
    "        self.dim_in = n_in\n",
    "        self.dim_out = n_out\n",
    "        # if params is provided, we look for the number of hidden layers and neuron per layer into that parameter (a dicttionary)\n",
    "        if (not params==None):\n",
    "            if (\"n_hidden_layers\" in params.keys()):\n",
    "                n_hidden_layers=params[\"n_hidden_layers\"]\n",
    "            if (\"n_neurons_per_hidden\" in params.keys()):\n",
    "                n_neurons_per_hidden=params[\"n_neurons_per_hidden\"]\n",
    "        self.n_per_hidden = n_neurons_per_hidden\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.weights = None \n",
    "        self.n_weights = None\n",
    "        self.init_random_params()\n",
    "        self.out = np.zeros(n_out)\n",
    "        #print(\"Creating a simple mlp with %d inputs, %d outputs, %d hidden layers and %d neurons per layer\"%(n_in, n_out,n_hidden_layers, n_neurons_per_hidden))\n",
    "\n",
    "    \n",
    "    def init_random_params(self):\n",
    "        if(self.n_hidden_layers > 0):\n",
    "            self.weights = [np.random.random((self.dim_in,self.n_per_hidden))] # In -> first hidden\n",
    "            self.bias = [np.random.random(self.n_per_hidden)] # In -> first hidden\n",
    "            for i in range(self.n_hidden_layers-1): # Hidden -> hidden\n",
    "                self.weights.append(np.random.random((self.n_per_hidden,self.n_per_hidden)))\n",
    "                self.bias.append(np.random.random(self.n_per_hidden))\n",
    "            self.weights.append(np.random.random((self.n_per_hidden,self.dim_out))) # -> last hidden -> out\n",
    "            self.bias.append(np.random.random(self.dim_out))\n",
    "        else:\n",
    "            self.weights = [np.random.random((self.dim_in,self.dim_out))] # Single-layer perceptron\n",
    "            self.bias = [np.random.random(self.dim_out)]\n",
    "        self.n_weights = np.sum([np.product(w.shape) for w in self.weights]) + np.sum([np.product(b.shape) for b in self.bias])\n",
    "\n",
    "    def get_parameters(self):\n",
    "        \"\"\"\n",
    "        Returns all network parameters as a single array\n",
    "        \"\"\"\n",
    "        flat_weights = np.hstack([arr.flatten() for arr in (self.weights+self.bias)])\n",
    "        return flat_weights\n",
    "\n",
    "    def set_parameters(self, flat_parameters):\n",
    "        \"\"\"\n",
    "        Set all network parameters from a single array\n",
    "        \"\"\"\n",
    "        i = 0 # index\n",
    "        to_set = []\n",
    "        self.weights = list()\n",
    "        self.bias = list()\n",
    "        if(self.n_hidden_layers > 0):\n",
    "            # In -> first hidden\n",
    "            w0 = np.array(flat_parameters[i:(i+self.dim_in*self.n_per_hidden)])\n",
    "            self.weights.append(w0.reshape(self.dim_in,self.n_per_hidden))\n",
    "            i += self.dim_in*self.n_per_hidden\n",
    "            for l in range(self.n_hidden_layers-1): # Hidden -> hidden\n",
    "                w = np.array(flat_parameters[i:(i+self.n_per_hidden*self.n_per_hidden)])\n",
    "                self.weights.append(w.reshape((self.n_per_hidden,self.n_per_hidden)))\n",
    "                i += self.n_per_hidden*self.n_per_hidden\n",
    "            # -> last hidden -> out\n",
    "            wN = np.array(flat_parameters[i:(i+self.n_per_hidden*self.dim_out)])\n",
    "            self.weights.append(wN.reshape((self.n_per_hidden,self.dim_out)))\n",
    "            i += self.n_per_hidden*self.dim_out\n",
    "            # Samefor bias now\n",
    "            # In -> first hidden\n",
    "            b0 = np.array(flat_parameters[i:(i+self.n_per_hidden)])\n",
    "            self.bias.append(b0)\n",
    "            i += self.n_per_hidden\n",
    "            for l in range(self.n_hidden_layers-1): # Hidden -> hidden\n",
    "                b = np.array(flat_parameters[i:(i+self.n_per_hidden)])\n",
    "                self.bias.append(b)\n",
    "                i += self.n_per_hidden\n",
    "            # -> last hidden -> out\n",
    "            bN = np.array(flat_parameters[i:(i+self.dim_out)])\n",
    "            self.bias.append(bN)\n",
    "            i += self.dim_out\n",
    "        else:\n",
    "            n_w = self.dim_in*self.dim_out\n",
    "            w = np.array(flat_parameters[:n_w])\n",
    "            self.weights = [w.reshape((self.dim_in,self.dim_out))]\n",
    "            self.bias = [np.array(flat_parameters[n_w:])]\n",
    "        self.n_weights = np.sum([np.product(w.shape) for w in self.weights]) + np.sum([np.product(b.shape) for b in self.bias])\n",
    "    \n",
    "    def predict(self,x):\n",
    "        \"\"\"\n",
    "        Propagage\n",
    "        \"\"\"\n",
    "        if(self.n_hidden_layers > 0):\n",
    "            #Input\n",
    "            a = np.matmul(x,self.weights[0]) + self.bias[0]\n",
    "            y = sigmoid(a)\n",
    "            # hidden -> hidden\n",
    "            for i in range(1,self.n_hidden_layers-1):\n",
    "                a = np.matmul(y, self.weights[i]) + self.bias[i]\n",
    "                y = sigmoid(a)\n",
    "            # Out\n",
    "            a = np.matmul(y, self.weights[-1]) + self.bias[-1]\n",
    "            out = tanh(a)\n",
    "            return out\n",
    "        else: # Simple monolayer perceptron\n",
    "            return tanh(np.matmul(x,self.weights[0]) + self.bias[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_and_save novelty_search.py\n",
    "\n",
    "# Cette cellule contient le code permettant de gérer novelty search. \n",
    "# Complétez les trous dans les balises <ANSWER></ANSWER>\n",
    "\n",
    "from scipy.spatial import KDTree\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class NovArchive:\n",
    "    \"\"\"Archive used to compute novelty scores.\"\"\"\n",
    "    def __init__(self, lbd, k=15):\n",
    "        self.all_bd=lbd\n",
    "        self.kdtree=KDTree(self.all_bd)\n",
    "        self.k=k\n",
    "        #print(\"Archive constructor. size = %d\"%(len(self.all_bd)))\n",
    "        \n",
    "    def update(self,new_bd):\n",
    "        oldsize=len(self.all_bd)\n",
    "        self.all_bd=self.all_bd + new_bd\n",
    "        self.kdtree=KDTree(self.all_bd)\n",
    "        #print(\"Archive updated, old size = %d, new size = %d\"%(oldsize,len(self.all_bd)))\n",
    "    def get_nov(self,bd, population=[]):\n",
    "\n",
    "        # A compléter pour calculer la nouveauté\n",
    "        # C'est la distance moyenne au self.k plus proches voisins parmi la population \n",
    "        # et l'archive, représentée ici par un kdtree (cf https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.KDTree.html)\n",
    "        #<ANSWER>\n",
    "\n",
    "        #</ANSWER>\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.all_bd)\n",
    "    \n",
    "def updateNovelty(population, offspring, archive, k=15, add_strategy=\"random\", _lambda=6, verbose=False):\n",
    "   \"\"\"Update the novelty criterion (including archive update) \n",
    "\n",
    "   Implementation of novelty search following (Gomes, J., Mariano, P., & Christensen, A. L. (2015, July). Devising effective novelty search algorithms: A comprehensive empirical study. In Proceedings of GECCO 2015 (pp. 943-950). ACM.).\n",
    "   :param population: is the set of indiv for which novelty needs to be computed\n",
    "   :param offspring: is the set of new individuals that need to be taken into account to update the archive (may be the same as population, but it may also be different as population may contain the set of parents)\n",
    "   :param k: is the number of nearest neighbors taken into account\n",
    "   :param add_strategy: is either \"random\" (a random set of indiv is added to the archive) or \"novel\" (only the most novel individuals are added to the archive).\n",
    "   :param _lambda: is the number of individuals added to the archive for each generation\n",
    "   The default values correspond to the one giving the better results in the above mentionned paper.\n",
    "\n",
    "   The function returns the new archive\n",
    "   \"\"\"\n",
    "   \n",
    "   # Novelty scores updates\n",
    "   if (archive) and (archive.size()>=k):\n",
    "       if (verbose):\n",
    "           print(\"Update Novelty. Archive size=%d\"%(archive.size())) \n",
    "       for ind in population:\n",
    "           ind.novelty=archive.get_nov(ind.bd, population)\n",
    "   else:\n",
    "       if (verbose):\n",
    "           print(\"Update Novelty. Initial step...\") \n",
    "       for ind in population:\n",
    "           ind.novelty=0.\n",
    "\n",
    "   if (verbose):\n",
    "       print(\"Fitness (novelty): \",end=\"\") \n",
    "       for ind in population:\n",
    "           print(\"%.2f, \"%(ind.novelty),end=\"\")\n",
    "       print(\"\")\n",
    "   if (len(offspring)<_lambda):\n",
    "       print(\"ERROR: updateNovelty, lambda(%d)<offspring size (%d)\"%(_lambda, len(offspring)))\n",
    "       return None\n",
    "\n",
    "   lbd=[]\n",
    "   # Update of the archive\n",
    "   if(add_strategy==\"random\"):\n",
    "       l=list(range(len(offspring)))\n",
    "       random.shuffle(l)\n",
    "       if (verbose):\n",
    "           print(\"Random archive update. Adding offspring: \"+str(l[:_lambda])) \n",
    "       lbd=[offspring[l[i]].bd for i in range(_lambda)]\n",
    "   elif(add_strategy==\"novel\"):\n",
    "       soff=sorted(offspring,lambda x:x.novelty)\n",
    "       ilast=len(offspring)-_lambda\n",
    "       lbd=[soff[i].bd for i in range(ilast,len(soff))]\n",
    "       if (verbose):\n",
    "           print(\"Novel archive update. Adding offspring: \")\n",
    "           for offs in soff[iLast:len(soff)]:\n",
    "               print(\"    nov=\"+str(offs.novelty)+\" fit=\"+str(offs.fitness.values)+\" bd=\"+str(offs.bd))\n",
    "   else:\n",
    "       print(\"ERROR: updateNovelty: unknown add strategy(%s), valid alternatives are \\\"random\\\" and \\\"novel\\\"\"%(add_strategy))\n",
    "       return None\n",
    "       \n",
    "   if(archive==None):\n",
    "       archive=NovArchive(lbd,k)\n",
    "   else:\n",
    "       archive.update(lbd)\n",
    "\n",
    "   return archive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile gym_fastsim_maze.py\n",
    "\n",
    "# Cette cellule contient le code complet de l'expérience de navigation dans le maze.\n",
    "# Complétez les trous dans les balises <ANSWER></ANSWER>\n",
    "\n",
    "\n",
    "import gym, gym_fastsim\n",
    "\n",
    "from deap import *\n",
    "import numpy as np\n",
    "from nn import SimpleNeuralControllerNumpy\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "from deap import algorithms\n",
    "from deap import base\n",
    "from deap import benchmarks\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "import argparse\n",
    "\n",
    "import array\n",
    "import random\n",
    "import operator\n",
    "import math\n",
    "\n",
    "from plot import *\n",
    "\n",
    "from scoop import futures\n",
    "\n",
    "from novelty_search import *\n",
    "\n",
    "weights=(-1.0,1.0)\n",
    "\n",
    "if (hasattr(creator, \"MyFitness\")):\n",
    "    # Deleting any previous definition (to avoid warning message)\n",
    "    print(\"Main: destroying myfitness\")\n",
    "    del creator.MyFitness\n",
    "creator.create(\"MyFitness\", base.Fitness, weights=(weights))\n",
    "\n",
    "if (hasattr(creator, \"Individual\")):\n",
    "    # Deleting any previous definition (to avoid warning message)\n",
    "    del creator.Individual\n",
    "creator.create(\"Individual\", list, fitness=creator.MyFitness)\n",
    "\n",
    "# Evaluation d'un réseau de neurones en utilisant gym\n",
    "def eval_nn(genotype, nbstep=2000, render=False, name=\"\"):\n",
    "    \"\"\"Evaluation d'une politique parametrée par le génotype\n",
    "\n",
    "    Evaluation d'une politique parametrée par le génotype\n",
    "    :param genotype: le paramètre de politique à évaluer\n",
    "    :param nbstep: le nombre maximum de pas de temps\n",
    "    :param render: affichage/sauvegarde de la trajectoire du robot\n",
    "    :param name: nom à donner au fichier de log\n",
    "    \"\"\"\n",
    "\n",
    "    # Cette fonction fait l'évaluation d'un genotype utilisé pour\n",
    "    # paraméter un réseau de neurones de structure fixe.\n",
    "    # En vue de l'expérience avec novelty_search, elle renvoie:\n",
    "    # - la fitness: distance à la sortie à minimiser (qui peut se récupérer dans la 4eme valeur de retour de la méthode step, qui est un dictionnaire dans lequel la clé \"dist_obj\" donne accès à l'opposé de la distance à la sortie)\n",
    "    # - le descripteur comportemental, qui est la position finale qui est accessible depuis le même dictionnaire (clé \"robot_pos\", dont il ne faut garder que les 2 premières composantes)\n",
    "    nn=SimpleNeuralControllerNumpy(5,2,2,10)\n",
    "    nn.set_parameters(genotype)\n",
    "    observation = env.reset()\n",
    "    old_pos=None\n",
    "    total_dist=0\n",
    "    if (render):\n",
    "        f=open(\"traj\"+name+\".log\",\"w\")\n",
    "\n",
    "    #<ANSWER>\n",
    "\n",
    "    #</ANSWER>\n",
    "\n",
    "\n",
    "def nsga2_NS(n=100, nbgen=200, IND_SIZE=10, variant=\"FIT\", MIN_V=-30, MAX_V=30, CXPB=0.6, MUTPB=0.3, verbose=False):\n",
    "    \n",
    "    # votre code contiendra donc des tests comme suit pour gérer la différence entre ces variantes:\n",
    "    if (hasattr(creator, \"MyFitness\")):\n",
    "        # Deleting any previous definition (to avoid warning message)\n",
    "        print(\"nsga2_NS: destroying myfitness\")\n",
    "        del creator.MyFitness\n",
    "\n",
    "    # Attention: le signe du poids associé à la fitness doit être adapté aux valeurs renvoyées par eval_nn (négatif si valeur à minimiser et positif si à maximiser)\n",
    "    if (variant==\"FIT+NS\"):\n",
    "        print(\"Creator: FIT+NS\")\n",
    "        creator.create(\"MyFitness\", base.Fitness, weights=(-1.0,1.0))\n",
    "    elif (variant==\"FIT\"):\n",
    "        print(\"Creator: FIT\")\n",
    "        creator.create(\"MyFitness\", base.Fitness, weights=(-1.0,))\n",
    "    elif (variant==\"NS\"):\n",
    "        print(\"Creator: NS\")\n",
    "        creator.create(\"MyFitness\", base.Fitness, weights=(1.0,))\n",
    "    else:\n",
    "        print(\"Variante inconnue: \"+variant)\n",
    "\n",
    "    if (hasattr(creator, \"Individual\")):\n",
    "        # Deleting any previous definition (to avoid warning message)\n",
    "        del creator.Individual\n",
    "    creator.create(\"Individual\", list, fitness=creator.MyFitness)\n",
    "\n",
    "\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"attribute\", random.uniform, MIN_V, MAX_V)\n",
    "    toolbox.register(\"individual\", tools.initRepeat, creator.Individual,\n",
    "            toolbox.attribute, n=IND_SIZE)\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "    toolbox.register(\"mate\", tools.cxSimulatedBinaryBounded, eta=15, low=MIN_V, up=MAX_V)\n",
    "    toolbox.register(\"mutate\", tools.mutPolynomialBounded, eta=15, low=MIN_V, up=MAX_V, indpb=1/IND_SIZE)\n",
    "    toolbox.register(\"select\", tools.selNSGA2, k=n)\n",
    "    toolbox.register(\"select_dcd\", tools.selTournamentDCD, k=n)\n",
    "    toolbox.register(\"evaluate\", eval_nn, render=True)\n",
    "    \n",
    "    toolbox.register(\"map\",futures.map)\n",
    "\n",
    "\n",
    "    population = toolbox.population(n=n)\n",
    "    paretofront = tools.ParetoFront()\n",
    "\n",
    "    # Permet de sauvegarder les descripteurs comportementaux de tous les individus rencontrés.\n",
    "    # vous pouvez tracer les descripteurs générés depuis une cellule de jupyter avec la commande:\n",
    "    # plot_points_file(\"bd.log\")\n",
    "    fbd=open(\"bd.log\",\"w\")\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
    "    fitnesses_bds = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, (fit, bd) in zip(invalid_ind, fitnesses_bds):\n",
    "        #print(\"Fit: \"+str(fit)) \n",
    "        #print(\"BD: \"+str(bd))\n",
    "   \n",
    "        # Complétez pour positionner fitness.values selon la variante choisie\n",
    "        #<ANSWER>\n",
    "\n",
    "        #</ANSWER>\n",
    "\n",
    "        fbd.write(\" \".join(map(str,bd))+\"\\n\")\n",
    "        fbd.flush()\n",
    "        \n",
    "    if paretofront is not None:\n",
    "        paretofront.update(population)\n",
    "\n",
    "    #print(\"Pareto Front: \"+str(paretofront))\n",
    "\n",
    "    k=15\n",
    "    add_strategy=\"random\"\n",
    "    lambdaNov=6\n",
    "\n",
    "    # Crée l'archive et mets à jour les champs ind.novelty de chaque individu\n",
    "    archive=updateNovelty(population,population,None,k,add_strategy,lambdaNov)\n",
    "    \n",
    "    # Selon la variante, complétez ind.fitness.values pour ajouter la valeur de ind.novelty qui vient d'être calculée\n",
    "    #<ANSWER>\n",
    "\n",
    "    #</ANSWER>\n",
    "            \n",
    "       \n",
    "    indexmin, valuemin = max(enumerate([i.fit for i in population]), key=operator.itemgetter(1))\n",
    "\n",
    "    # Pour le calcul des crowdingDistances si utilisation de selTournamentDCD\n",
    "    population[:] = toolbox.select(population)\n",
    "    \n",
    "    # Begin the generational process\n",
    "    for gen in range(1, nbgen + 1):\n",
    "        if (gen%10==0):\n",
    "            print(\"+\",end=\"\", flush=True)\n",
    "        else:\n",
    "            print(\".\",end=\"\", flush=True)\n",
    "\n",
    "        # Complétez avec un NSGA-2 en prenant soin de mettre à jour les calculs de nouveauté et d'ajouter les\n",
    "        # nouveautés à la fitness des individus.\n",
    " \n",
    "        # ATTENTION: dans la mise à jour de la nouveauté (updateNovelty), vérifiez bien la signification du premier et du 2eme argument.\n",
    "        # l'appel fait plus haut doit être adapté: la nouveauté de TOUS les individus doit être recalculée (parents+enfants)\n",
    "        # et les individus susceptibles d'être ajoutés à l'archive ne doivent être pris que parmi les enfants.\n",
    "        \n",
    "        #<ANSWER>\n",
    "\n",
    "        #</ANSWER>\n",
    "\n",
    "        # Update the hall of fame with the generated individuals\n",
    "        if paretofront is not None:\n",
    "            paretofront.update(population)\n",
    "\n",
    "\n",
    "        \n",
    "        # used to track the max value (useful in particular if using only novelty)\n",
    "        indexmin, newvaluemin = min(enumerate([i.fit for i in pq]), key=operator.itemgetter(1))\n",
    "        if (newvaluemin<valuemin):\n",
    "            valuemin=newvaluemin\n",
    "            print(\"Gen \"+str(gen)+\", new min ! min fit=\"+str(valuemin)+\" index=\"+str(indexmin))\n",
    "            eval_nn(pq[indexmin],True,\"gen%04d\"%(gen))\n",
    "    fbd.close()\n",
    "    return population, None, paretofront\n",
    "\n",
    "\n",
    "env = gym.make('FastsimSimpleNavigation-v0')\n",
    "\n",
    "if (__name__ == \"__main__\"):\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='Launch maze navigation experiment.')\n",
    "    parser.add_argument('--nbgen', type=int, default=200,\n",
    "                        help='number of generations')\n",
    "    parser.add_argument('--popsize', type=int, default=100,\n",
    "                        help='population size')\n",
    "    parser.add_argument('--res_dir', type=str, default=\"res\",\n",
    "                        help='basename of the directory in which to put the results')\n",
    "    parser.add_argument('--variant', type=str, default=\"FIT\", choices=['FIT', 'NS', 'FIT+NS'],\n",
    "                        help='variant to consider')\n",
    "\n",
    "    # Il vous est recommandé de gérer les différentes variantes avec cette variable. Les 3 valeurs possibles seront:\n",
    "    # \"FIT+NS\": expérience multiobjectif avec la fitness et la nouveauté (NSGA-2)\n",
    "    # \"NS\": nouveauté seule\n",
    "    # \"FIT\": fitness seule\n",
    "    # pour les variantes avec un seul objectif, il vous est cependant recommandé d'utiliser NSGA-2 car cela limitera la différence entre les variantes et cela \n",
    "    # vous fera gagner du temps pour la suite.\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    print(\"Number of generations: \"+str(args.nbgen))\n",
    "    nbgen=args.nbgen\n",
    "    print(\"Population size: \"+str(args.popsize))\n",
    "    popsize=args.popsize\n",
    "    print(\"Variant: \"+args.variant)\n",
    "    variant=args.variant\n",
    "\n",
    "    nn=SimpleNeuralControllerNumpy(5,2,2,10)\n",
    "    IND_SIZE=len(nn.get_parameters())\n",
    "\n",
    "    pop, logbook, paretofront= nsga2_NS(n=popsize, variant=variant, nbgen=nbgen, IND_SIZE=IND_SIZE)\n",
    "    #plot_pareto_front(paretofront, \"Final pareto front\")\n",
    "    for i,p in enumerate(paretofront):\n",
    "        print(\"Visualizing indiv \"+str(i)+\", fit=\"+str(p.fitness.values))\n",
    "        eval_nn(p,True)\n",
    "\n",
    "    env.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
